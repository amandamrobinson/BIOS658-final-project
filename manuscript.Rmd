---
title: "Method Comparison: LME vs. EdgeR for Crossover Design"
subtitle: "BIOS658 Final Project"
author: "Amanda Robinson"
date: "December 1, 2025"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, 
                      message = FALSE)
```

# Introduction

# Methods

# Results

## Quality Assessment

```{r data}
library(tidyverse)
library(GEOquery)
library(pheatmap)
library(limma)
library(sva)
library(edgeR)
library(ggrepel)
library(clusterProfiler)
library(org.Hs.eg.db)
library(AnnotationDbi)

#To track figure and table numbers
fig.num <- 0
tab.num <- 0

#Data obtained from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE231347
#read_csv() automatically unzips .gz files
gene_counts <- read_csv("GSE231347_counts.csv.gz")

gse <- getGEO("GSE231347", GSEMatrix = TRUE)
#Extract the expression set
gse_data <- gse[[1]]

# Create data frame from GEO phenoData.
phenotype <- pData(gse_data) %>%
  dplyr::rename(condition = `condition:ch1`, 
                mdd_phenotype = `mdd phenotype:ch1`, 
                timepoint = `time point:ch1`) %>%
  mutate(id = str_extract(title, "G[0-9]+")) %>%
  filter(timepoint == "T105") %>%
  group_by(id) %>%
  add_count() %>%
  filter(n > 1) %>%
  dplyr::select(title, id, mdd_phenotype, condition) %>%
  ungroup()

gene_counts <- gene_counts[, c("gene", phenotype$title)]
```

```{r qa-library-size}
library_size <- gene_counts %>%
  dplyr::select(-gene) %>%
  #Count the number of reads per sample
  colSums()

#Summary statistics for text
lib_summ <- round(quantile(library_size, c(0.25, 0.5, 0.75))/1000000, 1)
```

```{r qa-library-size-fig}
fig.num <- fig.num + 1

ggplot() + 
  geom_boxplot(aes(y = library_size/1000000)) +
  ylab("Library Size (Millions)") +
  ggtitle(paste0("Figure ", fig.num, ": Distribution of Library Size")) +
  theme_bw()
```

```{r qa-count-distribution}
gene_counts_long <- gene_counts %>%
  pivot_longer(-gene, names_to = "sample", values_to = "count") %>%
  mutate(log2_count = log2(count + 1))

log2_q3_range <- gene_counts_long %>%
  group_by(sample) %>%
  summarise(q3 = quantile(log2_count, 0.75)) %>%
  summarise(min = min(q3), 
            max = max(q3))
```

```{r qa-count-distribution-fig}
fig.num <- fig.num + 1

gene_counts_long %>%
  ggplot() + 
  geom_boxplot(aes(y = log2_count, x = sample)) +
  xlab("Sample") +
  ylab("Log2 Count + 1") +
  ggtitle(paste0("Figure ", fig.num, ": Distribution of Gene Count by Sample")) +
  theme_bw() +
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank())
```

```{r housekeeping}
genes <- gene_counts$gene

gene_counts <- gene_counts %>%
  dplyr::select(-gene) %>%
  as.matrix()

rownames(gene_counts) <- genes

# phenotype$title == colnames(gene_counts)
```


```{r qa-sample-correlation}
logCPM <- cpm(gene_counts, log = TRUE)

sample_cor <- cor(logCPM, method = "pearson")

gene_centered <- scale(t(gene_counts), center = TRUE, scale = FALSE)

annotation_data <- data.frame(
  Group = phenotype$mdd_phenotype,
  Visit = phenotype$condition, 
  id = phenotype$id,
  row.names = colnames(sample_cor) # Ensure row names match sample names
)

pheatmap(
  sample_cor,
  annotation_col = annotation_data,
  show_rownames = FALSE,
  show_colnames = FALSE,
  clustering_distance_rows = "euclidean",
  clustering_distance_cols = "euclidean",
  clustering_method = "complete",
  main = "Sample Correlation"
)
```

## Preprocessing

```{r preprocessing}
TypeCondition <- interaction(phenotype$mdd_phenotype, phenotype$condition)

#We will also need the design matrix
design <- model.matrix(~ TypeCondition)

#A. Format data as a DGEList
#We need to create a DGEList object to feed into the edgeR functions. 
y <- DGEList(counts = gene_counts, genes = rownames(gene_counts), 
             group = TypeCondition)

#B. Filter
#The documentation recommends filtering out genes with low or zero counts across
#all samples using this code. It also says you can include variables of 
#scientific interest (group in our case) in this step, which I choose to do 
#here.
keep <- filterByExpr(y, group = TypeCondition)
#We need to recalculate library size since we removed some genes
y <- y[keep, , keep.lib.sizes = FALSE]

#C. Normalization
#A few highly expressed genes may account for most of the library size, 
#resulting in under-sampling of genes with lower expression. We can address this
#issue through normalization. 
y <- normLibSizes(y)
```

## Batch Effect Correction

```{r sva}
mod0 <- model.matrix(~1, data = phenotype)  # null model (intercept-only)
# Estimate number of surrogate variables automatically (Leek method)
n.sv <- num.sv(y$counts, design, method = "be")

# Run svaseq to estimate surrogate variables
svseq <- svaseq(dat = y$counts, mod = design, mod0 = mod0, n.sv = n.sv)

# Remove surrogate variable effects using limma::removeBatchEffect (treat sv's 
#as covariates)
sv_mat <- svseq$sv
sva_corrected <- limma::removeBatchEffect(cpm(y, log = TRUE), 
                                          covariates = sv_mat)

colnames(sv_mat) <- paste0("SV", 1:ncol(sv_mat))

phenotype <- cbind(phenotype, sv_mat) 
```

```{r pca-tab}
tab.num <- tab.num + 1

pca <- prcomp(t(cpm(y, log = TRUE)), scale. = TRUE)
pca_sva <- prcomp(t(sva_corrected), scale. = TRUE)

rbind(summary(pca)$importance, 
      summary(pca_sva)$importance) %>%
  data.frame() %>%
  rownames_to_column(var = "Measure") %>%
  mutate(SVA = c(rep("No SVA", 3), rep("SVA", 3)), 
         Measure = str_remove(str_replace_all(Measure, "[.]", " "), 
                              "[0-9]+"), 
         across(is.numeric, round, 4)) %>%
  dplyr::select(SVA, Measure, contains("PC")) %>%
  DT::datatable(rownames = FALSE, 
                caption = paste0("Table ", tab.num, 
                                 ": PCA Variance Explained Before and After SVA Correction"),
                # Display only 10 rows per page
                options = list(pageLength = 10,
                # Optional: adds vertical scrolling if needed
                scrollY = "400px", 
                # Removes the search bar and only keeps table/pagination
                dom = 'tp', 
                # Enables pagination
                paging = TRUE, 
                scrollX = TRUE))
```

```{r pca-fig}
fig.num <- fig.num + 1

phenotype %>%
  dplyr::select(id, mdd_phenotype, condition) %>%
  mutate(pc1_nosva = pca$x[, 1], 
         pc2_nosva = pca$x[, 2], 
         pc1_sva = pca_sva$x[, 1], 
         pc2_sva = pca_sva$x[, 2]) %>%
  pivot_longer(c(-id, -mdd_phenotype, -condition), names_to = "method_pc", 
               values_to = "value") %>%
  separate_wider_delim(cols = method_pc, delim = "_", 
                       names = c("pc", "method")) %>%
  mutate(method = factor(method, levels = c("nosva", "sva"), 
                         labels = c("No SVA", "SVA")), 
         condition = factor(condition, levels = c("S", "NS"), 
                            labels = c("Stress Test", "Control"))) %>%
  pivot_wider(names_from = pc, values_from = value) %>%
  ggplot() + 
  geom_point(aes(x = pc1, y = pc2, color = mdd_phenotype)) +
  labs(title = paste0("Figiure ", fig.num, ": Principle Components by Condition and Batch Effect Correction"), 
       x = "PC1", 
       y = "PC2", 
       color = "Phagia") +
  theme_bw() +
  facet_grid(condition~method) +
  theme(legend.position = "bottom")
```

```{r hierarchical-clustering-1}
gene_iqr <- apply(cpm(y, log = TRUE), 1, IQR)
names(gene_iqr) <- y$genes$genes

# Determine the cutoff for the top 10% most variable genes
iqr_cutoff <- quantile(gene_iqr, 0.90)

# Select the genes that exceed the cutoff
# This set of genes will be used for BOTH the Before and After SVA plots.
top_10_percent_genes <- names(gene_iqr[gene_iqr >= iqr_cutoff])

fig.num <- fig.num + 1
pheatmap(
  logCPM[top_10_percent_genes, ], # Use UNCORRECTED data
  show_rownames = FALSE,
  show_colnames = FALSE,
  annotation = annotation_data, 
  clustering_distance_rows = "euclidean",
  clustering_distance_cols = "euclidean",
  main = paste0("Figure ", fig.num, 
                ": Clustering of Top 10% Genes (Before SVA Correction)"),
  fontsize = 8
)
```

```{r hierarchical-clustering-2}
fig.num <- fig.num + 1
pheatmap(
  sva_corrected[top_10_percent_genes, ], # Use CORRECTED data
  show_rownames = FALSE,
  show_colnames = FALSE,
  annotation = annotation_data, 
  clustering_distance_rows = "euclidean",
  clustering_distance_cols = "euclidean",
  main = paste0("Figure ", fig.num, 
                ": Clustering of Top 10% Genes (After SVA Correction)"),
  fontsize = 8
)
```

## Differential Expression Analysis

```{r differential-expression}
design_final <- model.matrix(as.formula(paste0("~ mdd_phenotype + condition + 
                                               mdd_phenotype * condition +", 
                                               paste0("SV", 1:ncol(sv_mat), 
                                                      collapse = " + "))), 
                             data = phenotype)

#D. Estimating Dispersion
#The authors recommend calculating the overall and tag-wise dispersion
y <- estimateDisp(y, design = design_final)

#E. Fit and Test Model
#I am using the quasi-likelihood pipeline
#"The QL F-tests provide more rigorous error rate control compared to methods 
#that do not fully account for the uncertainty in quasi-dispersion estimation."
fit_edgeR <- glmQLFit(y, design_final)

qlf_interaction <- glmQLFTest(fit_edgeR, coef = "mdd_phenotypeHypo:conditionS")

results <- topTags(qlf_interaction, 
                   #We want to keep any gene that meets our criteria
                   n = Inf, 
                   #We will use p-values to determine which genes to keep
                   sort.by = "PValue", 
                   #And us BH adjustment to control FDR
                   adjust.method = "BH")

top10 <- results$table[1:10, ]
```

```{r volcano-plot}
fig.num <- fig.num + 1

fc_threshold <- 1  # log2FC threshold
pval_threshold <- 0.05

results$table %>%
  mutate(neg_log10_p = -log10(PValue),
         status = case_when(PValue < pval_threshold & logFC >= 1 ~ 
                              "Upregulated",
                            PValue < pval_threshold & logFC <= -1 ~ 
                              "Downregulated",
                            TRUE ~ "Not Significant"), 
         label = ifelse(genes %in% top10$genes, genes, "")) %>% 
  ggplot() + 
  geom_point(aes(x = logFC, y = neg_log10_p, color = fct_rev(status))) +
  scale_color_manual(values = c("Upregulated" = "red",
                                "Downregulated" = "blue",
                                "Not Significant" = "grey50")) +
  # Add threshold lines
  geom_vline(xintercept = c(-fc_threshold, fc_threshold), 
             linetype = "dashed", color = "black", linewidth = 0.5) +
  geom_hline(yintercept = -log10(pval_threshold), 
             linetype = "dashed", color = "black", linewidth = 0.5) +
  geom_text_repel(aes(x = logFC, y = neg_log10_p, label = label),
                  size = 3, max.overlaps = 15) +
  labs(title = paste0("Figure ", fig.num, 
                      ": Volcano Plot with Top Gene Labels"), 
       x = "Log FC", 
       y = "- Log10 p-value", 
       color = "") +
  theme_bw()
```

```{r top10-tab}
tab.num <- tab.num + 1

top10 %>%
  dplyr::select(genes, logFC, PValue, FDR) %>%
  mutate(across(is.numeric, round, 4)) %>%
  dplyr::rename(Gene = genes) %>%
  DT::datatable(rownames = FALSE, 
                caption = paste0("Table ", tab.num, 
                                 ": Summary of Top 10 Differentially Expressed Genes"),
                # Display only 10 rows per page
                options = list(pageLength = 10,
                # Optional: adds vertical scrolling if needed
                scrollY = "400px", 
                # Removes the search bar and only keeps table/pagination
                dom = 'tp', 
                # Enables pagination
                paging = TRUE, 
                scrollX = TRUE))
```

```{r boxplot}
fig.num <- fig.num + 1

sva_corrected[top10$genes, ] %>%
  t() %>%
  data.frame() %>%
  rownames_to_column("title") %>%
  pivot_longer(-title, names_to = "gene", values_to = "count") %>%
  left_join(phenotype) %>%
  mutate(condition = factor(condition, levels = c("S", "NS"), 
                            labels = c("Stress Test", "Control"))) %>%
  ggplot() + 
  geom_boxplot(aes(x = mdd_phenotype, y = count, color = fct_rev(condition))) +
  labs(title = paste0("Figure ", fig.num, ": SVA Corrected Log CPM by MDD Phenotype, Condition, and Gene"), 
       x = "MDD Phenotype", 
       y = "SVA Corrected Log CPM", 
       color = "") +
  facet_wrap(~gene, ncol = 5) + 
  theme_bw() +
  theme(legend.position = "bottom")
```

## Functional Enrichment Analysis

```{r functional-enrichment-complete, message=FALSE, warning=FALSE}
# --- 1. Data Preparation (ENSEMBL to ENTREZID Mapping & Aggregation) ---

# Create a temporary data frame of LogFC values and ENSEMBL IDs
temp_df <- results$table %>%
  rownames_to_column(var = "ENSEMBL") %>%
  dplyr::select(ENSEMBL, logFC, PValue) 

# Convert Ensembl IDs to Entrez IDs (mapping table)
eg_mapping <- bitr(temp_df$ENSEMBL, 
           fromType="ENSEMBL",  
           toType="ENTREZID", 
           OrgDb="org.Hs.eg.db") %>%
  # Filter out multiple mappings for the same ENSEMBL ID
  distinct(ENSEMBL, .keep_all = TRUE) 

# Create the FINAL RANKED LIST (Unique Entrez IDs with Aggregated LogFC)
ranked_df_final <- temp_df %>%
  # Join LogFC results with the Entrez ID mapping table
  inner_join(eg_mapping, by = "ENSEMBL") %>%
  
  # Resolve the many-to-one problem: group by Entrez ID
  group_by(ENTREZID) %>%
  # Summarize by taking the max LogFC (largest signal)
  summarise(logFC = max(logFC)) %>%
  ungroup()

# Create the Final Ranked List for GSEA (sorted numeric vector)
ranked_gene_list <- ranked_df_final$logFC
names(ranked_gene_list) <- ranked_df_final$ENTREZID
ranked_gene_list <- sort(ranked_gene_list, decreasing = TRUE)

# Create the Final Significant List for ORA (the 7 strongest DEGs)
ora_degs_entrez <- temp_df %>%
  filter(PValue < 0.001) %>%
  inner_join(eg_mapping, by = "ENSEMBL") %>%
  distinct(ENTREZID, .keep_all = TRUE)

# --- 2. GSEA Analysis (KEGG and GO) ---

# GSEA for KEGG Pathways
gsea_results_kegg <- gseKEGG(
  geneList = ranked_gene_list, 
  organism = 'hsa', 
  nPerm = 1000, 
  pvalueCutoff = 0.25, 
  verbose = FALSE
)

# GSEA for Gene Ontology (GO - ALL domains)
gsea_results_go <- gseGO(
  geneList = ranked_gene_list, 
  OrgDb = org.Hs.eg.db, 
  ont = "ALL",         
  keyType = "ENTREZID",
  pvalueCutoff = 0.25, 
  verbose = FALSE
)

# --- 3. ORA Analysis (KEGG and GO) ---

# ORA for KEGG Pathways
ora_results_kegg <- enrichKEGG(
  gene = ora_degs_entrez$ENTREZID, 
  organism = 'hsa', 
  pvalueCutoff = 0.05, 
  qvalueCutoff = 0.20 
)

# ORA for Gene Ontology (GO - ALL domains)
ora_results_go <- enrichGO(
  gene = ora_degs_entrez$ENTREZID, 
  OrgDb = org.Hs.eg.db,
  ont = "ALL",                     
  keyType = "ENTREZID",
  pvalueCutoff = 0.05, 
  qvalueCutoff = 0.20
)

# --- 4. Final Results Combination and Visualization ---

tab.num <- tab.num + 1

# A. Process GSEA Results (KEGG & GO)
gsea_table_kegg <- gsea_results_kegg@result %>% mutate(Method = "GSEA_KEGG")
gsea_table_go <- gsea_results_go@result %>% mutate(Method = paste0("GSEA_", ONTOLOGY))

gsea_final_table <- bind_rows(gsea_table_kegg, gsea_table_go) %>%
  filter(p.adjust < 0.25) %>%
  dplyr::select(ID, Description, setSize, enrichmentScore, NES, pvalue, p.adjust, Method) %>%
  mutate(across(c(enrichmentScore, NES, pvalue, p.adjust), round, 4))

# B. Process ORA Results (KEGG & GO)
ora_table_kegg <- data.frame(ora_results_kegg) %>% mutate(Method = "ORA_KEGG")
ora_table_go <- data.frame(ora_results_go) %>% mutate(Method = paste0("ORA_", ONTOLOGY))

ora_final_table <- bind_rows(ora_table_kegg, ora_table_go) %>%
  filter(p.adjust < 0.20) %>%
  dplyr::select(ID, Description, Count, pvalue, p.adjust, Method) %>%
  mutate(setSize = Count,
         enrichmentScore = NA, NES = NA,
         across(c(pvalue, p.adjust), round, 4)) %>%
  dplyr::select(ID, Description, setSize, enrichmentScore, NES, pvalue, p.adjust, Method)

# C. Combine, Sort, and Display the Final Table
final_enrichment_results <- bind_rows(gsea_final_table, ora_final_table) %>%
  arrange(p.adjust)

DT::datatable(final_enrichment_results, 
              rownames = FALSE, 
              caption = paste0("Table ", tab.num, ": Significant Functional Enrichment Results (All Methods Combined)"),
              options = list(pageLength = 10, scrollX = TRUE))
```

# Discussion

# Bibliography
